{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('final_dataset.pickle', 'rb')    \n",
    "reportDF = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportDF.to_csv('final_dataset.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data from BIB entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Link', 'BibtexID', 'ResponsiblePerson', 'Title', 'StudyType',\n",
       "       'Dataset', 'Domain of tests [other]', 'DataPyramid', 'DatasetFeatures',\n",
       "       'Coupled/Decoupled', 'GroundTruthType', 'RecommendationType',\n",
       "       'GroupSizes', 'Baselines', 'GroupConstruction', 'GroupDuration',\n",
       "       'EvaluationDimensions', 'ReproducibleCode', 'ReproducibleData',\n",
       "       'ReproducibleGroups', 'ReproducibleEvalProtocol', 'Notes',\n",
       "       'ParsedDataset', 'DatasetHighLevel', 'ParsedDatasetHighLevel',\n",
       "       'ParsedBaselines', 'EvaluationDimensionsHighLevel', 'ParsedDomain',\n",
       "       'ParsedGroupConstruction', 'ParsedGroupConstructionHighLevel',\n",
       "       'ParsedGroupSizes', 'bib_text', 'bib_ID', 'bib_title', 'bib_authors',\n",
       "       'bib_year', 'bib_venue', 'bib_venue_long', 'bib_venue_type', 'bib_doi',\n",
       "       'bib_url', 'bib_publisher'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    23\n",
       "2021    21\n",
       "2022    20\n",
       "2019    17\n",
       "2017    10\n",
       "2023     9\n",
       "2018     7\n",
       "2016     5\n",
       "Name: bib_year, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.bib_year.value_counts()\n",
    "# decide on papers from 2016-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article          73\n",
       "inproceedings    33\n",
       "inbook            6\n",
       "Name: bib_venue_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.bib_venue_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elsevier BV                                                    33\n",
       "IEEE                                                           26\n",
       "ACM                                                            24\n",
       "Springer                                                       19\n",
       "CEUR-WS                                                         2\n",
       "Wiley                                                           2\n",
       "International World Wide Web Conferences Steering Committee     1\n",
       "Walter de Gruyter GmbH                                          1\n",
       "Research Square Platform LLC                                    1\n",
       "Hindawi Limited                                                 1\n",
       "Informa UK Limited                                              1\n",
       "IOS Press                                                       1\n",
       "Name: bib_publisher, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.bib_publisher.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expert Systems with Applications                             10\n",
       "Information Sciences                                          6\n",
       "IEEE Transactions on Knowledge and Data Engineering           5\n",
       "Knowledge-Based Systems                                       4\n",
       "Decision Support Systems                                      4\n",
       "Multimedia Tools and Applications                             4\n",
       "IEEE Access                                                   2\n",
       "ACM Transactions on Information Systems                       2\n",
       "Applied Intelligence                                          2\n",
       "IEEE Transactions on Neural Networks and Learning Systems     2\n",
       "Name: bib_venue, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.loc[reportDF.bib_venue_type == \"article\"].bib_venue.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecSys       6\n",
       "SIGIR        5\n",
       "UMAP         4\n",
       "CIKM         3\n",
       "ICDE         3\n",
       "WSDM         2\n",
       "SAC          1\n",
       "FUZZ-IEEE    1\n",
       "DASFAA       1\n",
       "BigData      1\n",
       "Name: bib_venue, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.loc[reportDF.bib_venue_type != \"article\"].bib_venue.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((401,), (305,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsList = []\n",
    "[ authorsList.extend(el) for el in reportDF[\"bib_authors\"] if isinstance(el, list)] \n",
    "allAuthors = pd.Series(authorsList)\n",
    "allAuthors.shape, allAuthors.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yin, Hongzhi                 7\n",
       "Lu, Jie                      4\n",
       "Yera, Raciel                 4\n",
       "Mart√≠nez, Luis               4\n",
       "Pitoura, Evaggelia           4\n",
       "Xu, Guandong                 3\n",
       "Zheng, Kai                   3\n",
       "Guo, Lei                     3\n",
       "Yu, Li                       3\n",
       "Leng, Youfang                3\n",
       "Chowdary, C. Ravindranath    3\n",
       "Peska, Ladislav              3\n",
       "Zhang, Yujie                 3\n",
       "Taleai, Mohammad             3\n",
       "Wang, Qinyong                3\n",
       "Guo, Zhiwei                  3\n",
       "Bahari Sojahrood, Zahra      3\n",
       "Castro, Jorge                3\n",
       "Meng, Xiangwu                3\n",
       "Stefanidis, Kostas           3\n",
       "Huang, Zhenhua               3\n",
       "Zhang, Guangquan             3\n",
       "Du, Yulu                     3\n",
       "Xu, Xin                      2\n",
       "Wang, Peipei                 2\n",
       "Chen, Yunwen                 2\n",
       "Lv, Pengtao                  2\n",
       "Yu, Keping                   2\n",
       "Wang, Lei                    2\n",
       "Li, Lin                      2\n",
       "Sisodia, Dilip Singh         2\n",
       "Pujahari, Abinash            2\n",
       "Guo, Junpeng                 2\n",
       "Shen, Yu                     2\n",
       "Li, Zhixu                    2\n",
       "Zhou, Xiaofang               2\n",
       "Wang, Haiyan                 2\n",
       "Tintarev, Nava               2\n",
       "Stratigi, Maria              2\n",
       "Dokoupil, Patrik             2\n",
       "Zhang, Bo                    2\n",
       "Minz, Sonajharia             2\n",
       "Tsaparas, Panayiotis         2\n",
       "Zheng, Nan                   2\n",
       "Wang, Wei                    2\n",
       "He, Zhixiang                 2\n",
       "Alzahrani, Ahmad A.          2\n",
       "Wang, Ru                     2\n",
       "Chow, Chi-Yin                2\n",
       "Zhang, Jia-Dong              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAuthors.value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Nodes and Edges for Force-directed Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these edges actually messed the graphs quite a bit so as a first solution, I just removed them.\n",
    "# Alternatively, we could figure out some way to decrease their weight\n",
    "def clean_list(listIn):\n",
    "    blacklist = [\"other\",\"item-based\",\"-\",\"Not clear\",\"Unclear / not specified\",\"unknown / not applicable\"]\n",
    "    return [i for i in listIn if i not in blacklist]\n",
    "\n",
    "\n",
    "# as an alternative, we can consider to use directed edges for some cases\n",
    "def jaccard_similarity(list1, list2):\n",
    "    # intersection of two sets\n",
    "    set1 = set(clean_list(list1))\n",
    "    set2 = set(clean_list(list2))\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    # Unions of two sets\n",
    "    union = len(set1.union(set2))\n",
    "    strRep = str(list(set1.intersection(set2)))\n",
    "    try:\n",
    "        return (intersection / union, strRep)\n",
    "    except:\n",
    "        return (0,\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each of reported values, get its best fit; then report on the average fit for list 1 \n",
    "# (i.e., to what extent are sizes used in list1 reflected in list2)\n",
    "def groupSizeSimilarity(list1, list2):\n",
    "    # intersection of two sets\n",
    "    dst = []\n",
    "    for i in list1:\n",
    "        dst_i = []\n",
    "        for j in list2:\n",
    "            d = abs(i-j) / np.max([i,j])\n",
    "            dst_i.append(d)\n",
    "        if len(dst_i) >0:\n",
    "            dst.append(np.min(dst_i))\n",
    "    if len(dst) >0:\n",
    "        meanDistance = np.mean(dst)\n",
    "        return 1 - meanDistance\n",
    "    else:\n",
    "        return 0 #i.e., one of the lists is empty  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Link', 'BibtexID', 'ResponsiblePerson', 'Title', 'StudyType',\n",
       "       'Dataset', 'Domain of tests [other]', 'DataPyramid', 'DatasetFeatures',\n",
       "       'Coupled/Decoupled', 'GroundTruthType', 'RecommendationType',\n",
       "       'GroupSizes', 'Baselines', 'GroupConstruction', 'GroupDuration',\n",
       "       'EvaluationDimensions', 'ReproducibleCode', 'ReproducibleData',\n",
       "       'ReproducibleGroups', 'ReproducibleEvalProtocol', 'Notes',\n",
       "       'ParsedDataset', 'DatasetHighLevel', 'ParsedDatasetHighLevel',\n",
       "       'ParsedBaselines', 'EvaluationDimensionsHighLevel', 'ParsedDomain',\n",
       "       'ParsedGroupConstruction', 'ParsedGroupConstructionHighLevel',\n",
       "       'ParsedGroupSizes', 'bib_text', 'bib_ID', 'bib_title', 'bib_authors',\n",
       "       'bib_year', 'bib_venue', 'bib_venue_long', 'bib_venue_type', 'bib_doi',\n",
       "       'bib_url', 'bib_publisher'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>BibtexID</th>\n",
       "      <th>ResponsiblePerson</th>\n",
       "      <th>Title</th>\n",
       "      <th>StudyType</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Domain of tests [other]</th>\n",
       "      <th>DataPyramid</th>\n",
       "      <th>DatasetFeatures</th>\n",
       "      <th>Coupled/Decoupled</th>\n",
       "      <th>...</th>\n",
       "      <th>bib_ID</th>\n",
       "      <th>bib_title</th>\n",
       "      <th>bib_authors</th>\n",
       "      <th>bib_year</th>\n",
       "      <th>bib_venue</th>\n",
       "      <th>bib_venue_long</th>\n",
       "      <th>bib_venue_type</th>\n",
       "      <th>bib_doi</th>\n",
       "      <th>bib_url</th>\n",
       "      <th>bib_publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td></td>\n",
       "      <td>LP</td>\n",
       "      <td>A novel group recommender system based on memb...</td>\n",
       "      <td>offline</td>\n",
       "      <td>ml100k</td>\n",
       "      <td>movies</td>\n",
       "      <td>No_groups</td>\n",
       "      <td></td>\n",
       "      <td>Coupled</td>\n",
       "      <td>...</td>\n",
       "      <td>Barzegar_Nozari_2020</td>\n",
       "      <td>A novel group recommender system based on memb...</td>\n",
       "      <td>[Barzegar Nozari, Reza, Koohi, Hamidreza]</td>\n",
       "      <td>2020</td>\n",
       "      <td>Knowledge-Based Systems</td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>10.1016/j.knosys.2020.106296</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.knosys.2020.106296</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td></td>\n",
       "      <td>LP</td>\n",
       "      <td>Member contribution-based group recommender sy...</td>\n",
       "      <td>offline</td>\n",
       "      <td>ml1m,ml100k,jester</td>\n",
       "      <td>movies,humor[tourism]</td>\n",
       "      <td>No_groups</td>\n",
       "      <td></td>\n",
       "      <td>Mixture or hybrid</td>\n",
       "      <td>...</td>\n",
       "      <td>Wang_2016</td>\n",
       "      <td>Member contribution-based group recommender sy...</td>\n",
       "      <td>[Wang, Wei, Zhang, Guangquan, Lu, Jie]</td>\n",
       "      <td>2016</td>\n",
       "      <td>Decision Support Systems</td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>10.1016/j.dss.2016.05.002</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.dss.2016.05.002</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td></td>\n",
       "      <td>LP</td>\n",
       "      <td>Content-based group recommender systems: A gen...</td>\n",
       "      <td>offline</td>\n",
       "      <td>ml100k,hetrec</td>\n",
       "      <td>movies</td>\n",
       "      <td>No_groups</td>\n",
       "      <td></td>\n",
       "      <td>Coupled</td>\n",
       "      <td>...</td>\n",
       "      <td>P_rez_Almaguer_2021</td>\n",
       "      <td>Content-based group recommender systems: A gen...</td>\n",
       "      <td>[P√©rez-Almaguer, Yilena, Yera, Raciel, Alzahra...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Expert Systems with Applications</td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>10.1016/j.eswa.2021.115444</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.eswa.2021.115444</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td></td>\n",
       "      <td>LP</td>\n",
       "      <td>Personalized hybrid recommendation for group o...</td>\n",
       "      <td>offline</td>\n",
       "      <td>ml10m</td>\n",
       "      <td>movies</td>\n",
       "      <td>No_groups</td>\n",
       "      <td></td>\n",
       "      <td>Coupled</td>\n",
       "      <td>...</td>\n",
       "      <td>Ka_k_2016</td>\n",
       "      <td>Personalized hybrid recommendation for group o...</td>\n",
       "      <td>[Ka≈°≈°√°k, Ondrej, Kompan, Michal, Bielikov√°, M√°...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Information Processing &amp;amp; Management</td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>10.1016/j.ipm.2015.10.001</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.ipm.2015.10.001</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "      <td></td>\n",
       "      <td>LP</td>\n",
       "      <td>Opinion Dynamics-Based Group Recommender Systems</td>\n",
       "      <td>offline</td>\n",
       "      <td>ml100k,ml1m</td>\n",
       "      <td>movies</td>\n",
       "      <td>No_groups</td>\n",
       "      <td></td>\n",
       "      <td>Coupled</td>\n",
       "      <td>...</td>\n",
       "      <td>Castro_2018</td>\n",
       "      <td>Opinion Dynamics-Based Group Recommender Systems</td>\n",
       "      <td>[Castro, Jorge, Lu, Jie, Zhang, Guangquan, Don...</td>\n",
       "      <td>2018</td>\n",
       "      <td>IEEE Transactions on Systems, Man, and Cyberne...</td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>10.1109/tsmc.2017.2695158</td>\n",
       "      <td>http://dx.doi.org/10.1109/tsmc.2017.2695158</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link BibtexID  \\\n",
       "1  https://www.sciencedirect.com/science/article/...            \n",
       "2  https://www.sciencedirect.com/science/article/...            \n",
       "3  https://www.sciencedirect.com/science/article/...            \n",
       "4  https://www.sciencedirect.com/science/article/...            \n",
       "6  https://ieeexplore.ieee.org/abstract/document/...            \n",
       "\n",
       "  ResponsiblePerson                                              Title  \\\n",
       "1                LP  A novel group recommender system based on memb...   \n",
       "2                LP  Member contribution-based group recommender sy...   \n",
       "3                LP  Content-based group recommender systems: A gen...   \n",
       "4                LP  Personalized hybrid recommendation for group o...   \n",
       "6                LP   Opinion Dynamics-Based Group Recommender Systems   \n",
       "\n",
       "  StudyType             Dataset Domain of tests [other] DataPyramid  \\\n",
       "1   offline              ml100k                  movies   No_groups   \n",
       "2   offline  ml1m,ml100k,jester   movies,humor[tourism]   No_groups   \n",
       "3   offline       ml100k,hetrec                  movies   No_groups   \n",
       "4   offline               ml10m                  movies   No_groups   \n",
       "6   offline         ml100k,ml1m                  movies   No_groups   \n",
       "\n",
       "  DatasetFeatures  Coupled/Decoupled  ...                bib_ID  \\\n",
       "1                            Coupled  ...  Barzegar_Nozari_2020   \n",
       "2                  Mixture or hybrid  ...             Wang_2016   \n",
       "3                            Coupled  ...   P_rez_Almaguer_2021   \n",
       "4                            Coupled  ...             Ka_k_2016   \n",
       "6                            Coupled  ...           Castro_2018   \n",
       "\n",
       "                                           bib_title  \\\n",
       "1  A novel group recommender system based on memb...   \n",
       "2  Member contribution-based group recommender sy...   \n",
       "3  Content-based group recommender systems: A gen...   \n",
       "4  Personalized hybrid recommendation for group o...   \n",
       "6   Opinion Dynamics-Based Group Recommender Systems   \n",
       "\n",
       "                                         bib_authors bib_year  \\\n",
       "1          [Barzegar Nozari, Reza, Koohi, Hamidreza]     2020   \n",
       "2             [Wang, Wei, Zhang, Guangquan, Lu, Jie]     2016   \n",
       "3  [P√©rez-Almaguer, Yilena, Yera, Raciel, Alzahra...     2021   \n",
       "4  [Ka≈°≈°√°k, Ondrej, Kompan, Michal, Bielikov√°, M√°...     2016   \n",
       "6  [Castro, Jorge, Lu, Jie, Zhang, Guangquan, Don...     2018   \n",
       "\n",
       "                                           bib_venue bib_venue_long  \\\n",
       "1                            Knowledge-Based Systems                  \n",
       "2                           Decision Support Systems                  \n",
       "3                   Expert Systems with Applications                  \n",
       "4            Information Processing &amp; Management                  \n",
       "6  IEEE Transactions on Systems, Man, and Cyberne...                  \n",
       "\n",
       "  bib_venue_type                       bib_doi  \\\n",
       "1        article  10.1016/j.knosys.2020.106296   \n",
       "2        article     10.1016/j.dss.2016.05.002   \n",
       "3        article    10.1016/j.eswa.2021.115444   \n",
       "4        article     10.1016/j.ipm.2015.10.001   \n",
       "6        article     10.1109/tsmc.2017.2695158   \n",
       "\n",
       "                                          bib_url bib_publisher  \n",
       "1  http://dx.doi.org/10.1016/j.knosys.2020.106296   Elsevier BV  \n",
       "2     http://dx.doi.org/10.1016/j.dss.2016.05.002   Elsevier BV  \n",
       "3    http://dx.doi.org/10.1016/j.eswa.2021.115444   Elsevier BV  \n",
       "4     http://dx.doi.org/10.1016/j.ipm.2015.10.001   Elsevier BV  \n",
       "6     http://dx.doi.org/10.1109/tsmc.2017.2695158          IEEE  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_width_factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = reportDF\n",
    "#item1, item2, edgeType, edgeWeight\n",
    "edgeListAuthors = []\n",
    "edgeListVenue = []\n",
    "edgeListYear = []\n",
    "\n",
    "for i,r1 in raw_data.iterrows():\n",
    "    for j,r2 in raw_data.iterrows():\n",
    "        if i < j:\n",
    "            val, simAuthors = jaccard_similarity(r1[\"bib_authors\"],r2[\"bib_authors\"])\n",
    "            if val > 0:\n",
    "                 \n",
    "                edgeListAuthors.append({\"source\":i, \"target\":j, \"type\":\"same_authors\",\"value\":val*link_width_factor, \"label\":simAuthors})\n",
    "\n",
    "            if r1[\"bib_venue\"] == r2[\"bib_venue\"]:\n",
    "                edgeListVenue.append({\"source\":i, \"target\":j, \"type\":\"same_venue\",\"value\":1.0*link_width_factor, \"label\":r1[\"bib_venue\"]}) \n",
    "            if r1[\"bib_year\"] == r2[\"bib_year\"]:\n",
    "                edgeListYear.append({\"source\":i, \"target\":j, \"type\":\"same_year\",\"value\":1.0*link_width_factor, \"label\":r1[\"bib_year\"]})                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r1 in raw_data.iterrows():\n",
    "    for j,r2 in raw_data.iterrows():\n",
    "        if int(r2[\"bib_year\"]) - int(r1[\"bib_year\"]) >0: #first is older\n",
    "            val = 1/( 1 + int(r2[\"bib_year\"]) - int(r1[\"bib_year\"]))\n",
    "            if val > 0.1:\n",
    "                label = str(r1[\"bib_year\"]) + \" vs.\" + str(r2[\"bib_year\"])\n",
    "                edgeListYear.append({\"source\":i, \"target\":j, \"type\":\"year_olderThan\",\"value\":val*link_width_factor, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeList = []\n",
    "for i,r1 in raw_data.iterrows():\n",
    "    nodeList.append({\"id\":i, \"label\":r1[\"bib_ID\"], \"title\":r1[\"bib_title\"], \"year\":r1[\"bib_year\"], \"venue\":r1[\"bib_venue\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_file = open(\"graphEdgesAuthors.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListAuthors}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesVenue.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListVenue}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesYear.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListYear}, out_file, indent = 3)   \n",
    "out_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(edgeListAuthors).to_csv(\"graphEdgesAuthors.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListVenue).to_csv(\"graphEdgesVenue.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListYear).to_csv(\"graphEdgesYear.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there might be some inconsistencies due to duplicates drop (I'll mention it during the meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item1, item2, edgeType, edgeWeight\n",
    "edgeListBaselines = []\n",
    "edgeListDatasets = []\n",
    "edgeListGroupConstruction = []\n",
    "edgeListEvalMetrics = []\n",
    "edgeListOther = []\n",
    "\n",
    "for i,r1 in raw_data.iterrows():\n",
    "    for j,r2 in raw_data.iterrows():\n",
    "        if i < j:\n",
    "            val, simBaselines = jaccard_similarity(r1[\"ParsedBaselines\"],r2[\"ParsedBaselines\"])\n",
    "            if val > 0:\n",
    "                edgeListBaselines.append({\"source\":i, \"target\":j, \"type\":\"same_baseliens\",\"value\":val*link_width_factor, \"label\":simBaselines})\n",
    "                \n",
    "            val, simDatasets = jaccard_similarity(r1[\"ParsedDatasetHighLevel\"],r2[\"ParsedDatasetHighLevel\"])\n",
    "            if val > 0:\n",
    "                edgeListDatasets.append({\"source\":i, \"target\":j, \"type\":\"same_datasets\",\"value\":val*link_width_factor, \"label\":simDatasets}) \n",
    "                \n",
    "            val, simGCS = jaccard_similarity(r1[\"ParsedGroupConstructionHighLevel\"],r2[\"ParsedGroupConstructionHighLevel\"])\n",
    "            if val > 0:\n",
    "                edgeListGroupConstruction.append({\"source\":i, \"target\":j, \"type\":\"same_groupConstruction\",\"value\":val*link_width_factor, \"label\":simGCS}) \n",
    "\n",
    "            val, simEvDim = jaccard_similarity(r1[\"EvaluationDimensionsHighLevel\"],r2[\"EvaluationDimensionsHighLevel\"])\n",
    "            if val > 0:\n",
    "                edgeListEvalMetrics.append({\"source\":i, \"target\":j, \"type\":\"similar_EvalMetrics\",\"value\":val*link_width_factor, \"label\":simEvDim}) \n",
    "                \n",
    "                \n",
    "            if r1[\"StudyType\"] == r2[\"StudyType\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_studyType\",\"value\":1.0*link_width_factor, \"label\":r1[\"StudyType\"]}) \n",
    "            if r1[\"DataPyramid\"] == r2[\"DataPyramid\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_dataPyramid\",\"value\":1.0*link_width_factor, \"label\":r1[\"DataPyramid\"]}) \n",
    "            if r1[\"Coupled/Decoupled\"] == r2[\"Coupled/Decoupled\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_evalStyle\",\"value\":1.0*link_width_factor, \"label\":r1[\"Coupled/Decoupled\"]})                 \n",
    "            if r1[\"GroundTruthType\"] == r2[\"GroundTruthType\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_groundTruth\",\"value\":1.0*link_width_factor, \"label\":r1[\"GroundTruthType\"]})                 \n",
    "            if r1[\"RecommendationType\"] == r2[\"RecommendationType\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_recsType\",\"value\":1.0*link_width_factor, \"label\":r1[\"RecommendationType\"]})                 \n",
    "            if r1[\"GroupDuration\"] == r2[\"GroupDuration\"]:\n",
    "                edgeListOther.append({\"source\":i, \"target\":j, \"type\":\"same_groupDuration\",\"value\":1.0*link_width_factor, \"label\":r1[\"GroupDuration\"]})                 \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item1, item2, edgeType, edgeWeight\n",
    "edgeListGroupSizes = []\n",
    "\n",
    "for i,r1 in raw_data.iterrows():\n",
    "    for j,r2 in raw_data.iterrows():\n",
    "            val = groupSizeSimilarity(r1[\"ParsedGroupSizes\"],r2[\"ParsedGroupSizes\"])\n",
    "            if val > 0.2:\n",
    "                label = str(r1[\"ParsedGroupSizes\"]) + \"vs.\" + str(r2[\"ParsedGroupSizes\"])\n",
    "                edgeListGroupSizes.append({\"source\":i, \"target\":j, \"type\":\"similar_groupSizes\",\"value\":val*link_width_factor, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_file = open(\"graphEdgesDatasets.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListDatasets}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesBaselines.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListBaselines}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesGroupConstruction.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListGroupConstruction}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesEvalMetrics.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListEvalMetrics}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesGroupSizes.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListGroupSizes}, out_file, indent = 3)   \n",
    "out_file.close() \n",
    "\n",
    "out_file = open(\"graphEdgesOther.json\", \"w\") \n",
    "json.dump({\"nodes\":nodeList, \"links\":edgeListOther}, out_file, indent = 3)   \n",
    "out_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(edgeListDatasets).to_csv(\"graphEdgesDatasets.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListBaselines).to_csv(\"graphEdgesBaselines.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListGroupConstruction).to_csv(\"graphEdgesGroupConstruction.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListEvalMetrics).to_csv(\"graphEdgesEvalMetrics.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListGroupSizes).to_csv(\"graphEdgesGroupSizes.csv\", sep=\";\")\n",
    "pd.DataFrame(edgeListOther).to_csv(\"graphEdgesOther.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
